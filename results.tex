%!TEX root = Memoria_TFM.tex
%\minitoc
%\mtcskip

\begin{small}
\emph{In this chapter the results obtained are presented as well as the training process that is going to be discussed.\\}
\end{small}
% The hole process (training and testing) has been realized three times to have more general results.

\section{Training and validating process}
The convolutional neural networks has been trained independently for each database as is explained in \ref{Final_archi}. In this section, the training and validation process is presented for each database.\\
\subsection{CASIA Image database}
In figure \ref{fig:ejecucion2_casia_im_train} the cost and training are represented (\ref{fig:ejecucion2_casia_im_train_cost} and \ref{fig:ejecucion2_casia_im_train_cost} respectively). The training process converge in a low values, smaller than 0.0001; while the validation process converges in 20\% error from the 250th epoch. The iterations where the training process oscillates sharply agree with the epochs where the cost oscillates sharply too. After those oscillations, the validation gets constant and the training error variates in its lowest values.\\
\begin{figure}[htb]
\centering
		\subfigure[Cost at training]{\includegraphics[width=0.47\textwidth]{images/ejecucion2_general/resultados_casia_images/cost.png}\label{fig:ejecucion2_casia_im_train_cost}}
		\subfigure[Error at validation]{\includegraphics[width=0.47\textwidth]{images/ejecucion2_general/resultados_casia_images/error.png}\label{fig:ejecucion2_casia_im_train_error}}
\caption{Cost (a) and error (b) at training CASIA image database}
\label{fig:ejecucion2_casia_im_train}
\end{figure}

The saved model to realize the test performance is the obtained at iteration 1176 with a 15\% validation error.\\

\subsection{CASIA Video database}
The cost and error obtained at training and validation processed when CASIA video database is used, are represented in figure \ref{fig:ejecucion2_casia_vid_train}. The minimum cost is almost 0 and is obtained before 2000th iteration, as is represented in figure \ref{fig:ejecucion2_casia_vid_train_cost}. The validation converges at the same time as the training, where oscillate between 7\% and 6\%.\\
\begin{figure}[htb]
\centering
		\subfigure[Cost at training]{\includegraphics[width=0.47\textwidth]{images/ejecucion2_general/resultados_casia_videos/cost.png}\label{fig:ejecucion2_casia_vid_train_cost}}
		\subfigure[Error at validation]{\includegraphics[width=0.47\textwidth]{images/ejecucion2_general/resultados_casia_videos/error.png}\label{fig:ejecucion2_casia_vid_train_error}}
\caption{Cost (a) and error (b) at training CASIA video database}
\label{fig:ejecucion2_casia_vid_train}
\end{figure}

The best validation performance is obtained at iteration 2240 with a 5.71\% validation error.\\

\subsection{FRAV database}
The cost and error obtained at training and validation processes respectively are represented in figure \ref{fig:ejecucion2_frav_train}. The cost, that could be seen in figure \ref{fig:ejecucion2_frav_train_cost} get a low value, when it converges before the 5000th iteration, the cost obtained is 0.000001. The validation error, represented in figure \ref{fig:ejecucion2_frav_train_cost}, fluctuate a lot, the curve should decrease, but it does not and in 200 epoch, the error is constant in 11.25\%. The generalization at validation is not very good and before the 100th epoch the network seems to overfit.\\
\begin{figure}[htb]
\centering
		\subfigure[Cost at training]{\includegraphics[width=0.47\textwidth]{images/ejecucion2_general/resultados_frav/cost.png}\label{fig:ejecucion2_frav_train_cost}}
		\subfigure[Error at validation]{\includegraphics[width=0.47\textwidth]{images/ejecucion2_general/resultados_frav/error.png}\label{fig:ejecucion2_frav_train_error}}
\caption{Cost (a) and error (b) at training RGB FRAV image database}
\label{fig:ejecucion2_frav_train}
\end{figure}

The best validation score of 1.25\% has been obtained at iteration 2016 which is saved as model for testing.\\

\subsection{FRAV RGB+NIR (feature level) database}
The RGB+NIR FRAV database, whose images has been added before the training process, has a cost and error which is represented in figure \ref{fig:ejecucion2_frav_feat_train}. The cost at training, that could be seen in \ref{fig:ejecucion2_frav_feat_train_cost} oscillates in the 3500 first iterations until decrease its value to 0 in the last 100 iterations. The cost at validation oscillates in the same oscillation cost period, where the value gets 0\% in different times. After this, the value gets in 3,3\%. Although the validation performance does not decrease in a desirable way, it gets a 0\% error which means that the generalization is very good.\\
\begin{figure}[htb]
\centering
		\subfigure[Cost at training]{\includegraphics[width=0.47\textwidth]{images/ejecucion2_general/resultados_frav_rgb_nir/cost.png}\label{fig:ejecucion2_frav_feat_train_cost}}
		\subfigure[Error at validation]{\includegraphics[width=0.47\textwidth]{images/ejecucion2_general/resultados_frav_rgb_nir/error.png}\label{fig:ejecucion2_frav_feat_train_error}}
\caption{Cost (a) and error (b) at training RGB and NIR FRAV (feature level) image database}
\label{fig:ejecucion2_frav_feat_train}
\end{figure}

The best model is obtained at 702 iteration, when the validation gets 0\% for the first time.\\

\subsection{FRAV RGB+NIR (classification level) database}
In figure \ref{fig:ejecucion2_frav_clas_train} is represented the training cost and the validation error when the database has been trained, first the RGB subset and then NIR subset. This two subsets are trained independently and features of each best model are concatenated to test performance.\\

\begin{figure}[htb]
\centering
		\subfigure[Cost at training RGB subset]{\includegraphics[width=0.47\textwidth]{images/ejecucion2_general/resultados_frav_concatenated/cost_rgb.png}\label{fig:ejecucion2_frav_clas_train_cost_rgb}}
		\subfigure[Error at validation RGB subset]{\includegraphics[width=0.47\textwidth]{images/ejecucion2_general/resultados_frav_concatenated/error_rgb.png}\label{fig:ejecucion2_frav_clas_train_error_rgb}}
		\subfigure[Cost at training NIR subset]{\includegraphics[width=0.47\textwidth]{images/ejecucion2_general/resultados_frav_concatenated/cost_nir.png}\label{fig:ejecucion2_frav_clas_train_cost_nir}}
		\subfigure[Error at validation NIR subset]{\includegraphics[width=0.47\textwidth]{images/ejecucion2_general/resultados_frav_concatenated/error_nir.png}\label{fig:ejecucion2_frav_clas_train_error_nir}}
\caption{Cost (a) and error (b) at training RGB subset, cost (c) and error (d) at training NIR subset for FRAV (RGB+NIR at classification level) image database}
\label{fig:ejecucion2_frav_clas_train}
\end{figure}

In RGB and NIR cost training, after decreasing its value got a very low value as in others databases. About the cost in validation, in both cases gets 0\%, the difference is that in RGB, this lowest value is gotten twice at epoch 124 and 125 and then the value is increased until get constant at 10\%, what seems an overfit. However, in NIR validation error, it oscillates until gets 0\% value and is constant until the end.\\

The best RGB model is the obtained at iteration 3347, when 0.0\% is gotten at validation error. The best NIR model is the obtained at iteration 674, the first time that the validation error gets 0\%.\\

\subsection{MFSD database}
The training results obtained for MFSD database are represented in figure \ref{fig:ejecucion2_mfsd_train}. The cost decreases slowly until get a desirable cost value, near to 0\%. The validation error curve graph (figure \ref{fig:ejecucion2_mfsd_error}) is not as good as the cost curve. The lower error value is obtained in the first 100 iterations, which is constant and then is increased until 35\%.\\

\begin{figure}[htb]
\centering
		\subfigure[Cost at training]{\includegraphics[width=0.47\textwidth]{images/ejecucion2_general/resultados_mfsd/cost.png}\label{fig:ejecucion2_mfsd_cost}}
		\subfigure[Error at validation]{\includegraphics[width=0.47\textwidth]{images/ejecucion2_general/resultados_mfsd/error.png}\label{fig:ejecucion2_mfsd_error}}
\caption{Cost (a) and error (b) at training MFSD image database}
\label{fig:ejecucion2_mfsd_train}
\end{figure}

The best model is the obtained at iteration 7, in the first epoch, where the validation error is 14,28\%.\\

\section{Testing process}
From the best CNN model, for each database, A SVM (with lineal and RBF kernel), KNN, Decision Tree and logistic regression has been trained. Also the testing has been realized after training a LDA and PCA (which have been trained too for each database) with each classifier.\\

The test performance for each classifier, has been realized after chosen the best classifier model.  The results are going to be exposed independently of each database and then compared among all databases.\\

Best obtained results are highlighted in bold in each table.\\

\subsection{CASIA Image database}
The results obtained testing the CNN model for CASIA image database are shown. \\

\begin{table}[htb]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{|c|c|c||c|c|c||c|c|c|}
\hline
\rowcolor[HTML]{ECF4FF}
Classifier                                                                   & APCR & BPCR  & \begin{tabular}[|c]{@{}c@{}}Classifier + PCA\\ nº components = 103\end{tabular} & APCR & BPCR  & \begin{tabular}[|c]{@{}c@{}}Classifier + LDA\\ nº components = 1\end{tabular}   & APCR & BPCR  \\ \hline
\begin{tabular}[c]{@{}c@{}}SVM - RBF\\ C = 0.5\end{tabular}                  & 0    & 0.125 & \begin{tabular}[c]{@{}c@{}}SVM - RBF\\ C = 1\end{tabular}                      & 0    & 0.125 & \begin{tabular}[c]{@{}c@{}}SVM - RBF\\ C = 0.5\end{tabular}                    & 0    & 0.125 \\ \hline
\begin{tabular}[c]{@{}c@{}}SVM - lineal\\ C = 0.001\end{tabular}             & 0    & 1     & \begin{tabular}[c]{@{}c@{}}SVM - lineal\\ C = 0.001\end{tabular}               & 0    & 1     & \begin{tabular}[c]{@{}c@{}}SVM - lineal\\ C = 0.005\end{tabular}               & 0    & 1     \\ \hline
\begin{tabular}[c]{@{}c@{}}KNN\\ k = 2\end{tabular}                          & 0    & 0.125 & \begin{tabular}[c]{@{}c@{}}KNN\\ k = 2\end{tabular}                            & 0    & 0.125 & \begin{tabular}[c]{@{}c@{}}KNN\\ k = 4\end{tabular}                            & 0    & 0.125 \\ \hline
\begin{tabular}[c]{@{}c@{}}Decision Tree\\ Depth =  12\end{tabular}          & 0    & 0.5   & \begin{tabular}[c]{@{}c@{}}Decision Tree\\ Depth = 4\end{tabular}              & 0    & 0.125 & \begin{tabular}[c]{@{}c@{}}Decision Tree\\ Depth = 2\end{tabular}              & 0    & 0.125 \\ \hline
\begin{tabular}[c]{@{}c@{}}Logistic Regression\\ l. rate = 0.01\end{tabular} & 0    & 0.125 & \begin{tabular}[c]{@{}c@{}}Logistic Regression\\ l. rate = 0.0001\end{tabular} & 0    & 0.125 & \begin{tabular}[c]{@{}c@{}}Logistic Regression\\ l. rate = 0.0001\end{tabular} & 0    & 0.125 \\ \hline
\end{tabular} }
\caption{APCR and BPCR classifying results using CASIA image database}
\label{APCR_BPCR_CASIA_im}
\end{table}

In table \ref{APCR_BPCR_CASIA_im} are exposed the APCR and BPCR parameters for each classifier. All the attacks samples are rightly classified because APCR value is 0. The number of genuine samples misclassified is what changes, it gets 1 for SVM with kernel lineal, all the positives samples have been misclassified, and decision tree whose number of misclassified real user are 4 (the half of the total real samples of the test subset). The rest of the classifiers takes a 0.125 APCR value, just one sample is misclassified, the same sample which could be seen in figure \ref{fig:casia_im_miscl}.\\% :('False Negative: ', 'databases/Casia database Fixed/Real/41.jpg')\\

With respect to APCR and BPCR it is not possible to get the best combination with which the results are better, because most of classifiers works correctly.\\

\begin{figure}[htb]
\centering
\includegraphics[width=0.2\textwidth]{images_databases/casia_real_41.jpg}
\caption{Casia image misclassified sample.} \label{fig:casia_im_miscl}
\end{figure}

\subsection{CASIA Video database}
Next analyzed results are from CASIA video database.\\

\begin{table}[htb]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{|c|c|c||c|c|c||c|c|c|}
\hline
\rowcolor[HTML]{ECF4FF}
Classifier                                                                   & APCR & BPCR & \begin{tabular}[|c]{@{}c@{}}Classifier + PCA\\ nº components = 283\end{tabular} & APCR & BPCR & \begin{tabular}[|c]{@{}c@{}}Classifier + LDA\\ nº components = 1\end{tabular}  & APCR & BPCR \\ \hline
\begin{tabular}[c]{@{}c@{}}SVM - RBF\\ C = 0.1\end{tabular}                  & 0.14 & 0.53 & \begin{tabular}[c]{@{}c@{}}SVM - RBF\\ C = 0.5\end{tabular}                    & 0.17 & 0.46 & \begin{tabular}[c]{@{}c@{}}SVM - RBF\\ C = 0.05\end{tabular}                  & \textbf{0.16} & \textbf{0.44} \\ \hline
\begin{tabular}[c]{@{}c@{}}SVM - lineal\\ C = 0.001\end{tabular}             & 0    & 1    & \begin{tabular}[c]{@{}c@{}}SVM - lineal\\ C = 0.001\end{tabular}               & 0    & 1    & \begin{tabular}[c]{@{}c@{}}SVM - lineal\\ C = 0.001\end{tabular}              & 0    & 1    \\ \hline
\begin{tabular}[c]{@{}c@{}}KNN\\ k = 2\end{tabular}                          & 0.19 & 0.42 & \begin{tabular}[c]{@{}c@{}}KNN\\ k = 2\end{tabular}                            & 0.2  & 0.42 & \begin{tabular}[c]{@{}c@{}}KNN\\ k = 2\end{tabular}                           & 0.16 & 0.47 \\ \hline
\begin{tabular}[c]{@{}c@{}}Decision Tree\\ Depth =  2\end{tabular}           & 0.19 & 0.49 & \begin{tabular}[c]{@{}c@{}}Decision Tree\\ Depth = 2\end{tabular}              & 0.15 & 0.53 & \begin{tabular}[c]{@{}c@{}}Decision Tree\\ Depth = 2\end{tabular}             & 0.15 & 0.46 \\ \hline
\begin{tabular}[c]{@{}c@{}}Logistic Regression\\ l. rate = 0.01\end{tabular} & 0.15 & 0.49 & \begin{tabular}[c]{@{}c@{}}Logistic Regression\\ l. rate = 0.005\end{tabular}  & 0.23 & 0.34 & \begin{tabular}[c]{@{}c@{}}Logistic Regression\\ l. rate = 0.005\end{tabular} & 0.23 & 0.37 \\ \hline
\end{tabular} }
\caption{APCR and BPCR classifying results using CASIA video database}
\label{APCR_BPCR_CASIA_vid}
\end{table}

In table \ref{APCR_BPCR_CASIA_vid} APCR and BPCR results are summarized. The best result has been obtained with SVM classifier and kernel RBF (C= 0.05) after applying LDA with 1 component. The worst values obtained are the SVM with lineal kernel, no matters if PCA or LDA have been used, because all the positives samples have been classified as negatives. \\

From the table it is not possible to know if LDA and PCA are significant because with some classifiers APCR and BPCR results have been improve or worsened.\\

Also The last conclusion that could be gotten from the table is that Attacks samples are better classified that genuine samples, it is due to the fact that has been trained with more negative samples.\\

\subsection{FRAV database}
The RGB FRAV database results are presented and analyzed.\\

\begin{table}[htb]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{|c|c|c||c|c|c||c|c|c|}
\hline
\rowcolor[HTML]{ECF4FF}
Classifier                                                                   & APCR & BPCR & \begin{tabular}[|c]{@{}c@{}}Classifier + PCA\\ nº components = 463\end{tabular} & APCR & BPCR & \begin{tabular}[|c]{@{}c@{}}Classifier + LDA\\ nº components = 1\end{tabular}  & APCR & BPCR \\ \hline
\begin{tabular}[c]{@{}c@{}}SVM - RBF\\ C = 0.5\end{tabular}                  & 0.06 & 0.06 & \begin{tabular}[c]{@{}c@{}}SVM - RBF\\ C = 1\end{tabular}                      & \textbf{0.04} & \textbf{0.06} & \begin{tabular}[c]{@{}c@{}}SVM - RBF\\ C = 0.1\end{tabular}                   & 0.05 & 0.06 \\ \hline
\begin{tabular}[c]{@{}c@{}}SVM - lineal\\ C = 0.005\end{tabular}             & 0    & 1    & \begin{tabular}[c]{@{}c@{}}SVM - lineal\\ C = 0.005\end{tabular}               & 0    & 1    & \begin{tabular}[c]{@{}c@{}}SVM - lineal\\ C = 0.5\end{tabular}                & 0.05 & 0.06 \\ \hline
\begin{tabular}[c]{@{}c@{}}KNN\\ k = 16\end{tabular}                         & 0.07 & 0.06 & \begin{tabular}[c]{@{}c@{}}KNN\\ k = 26\end{tabular}                           & 0.06 & 0.06 & \begin{tabular}[c]{@{}c@{}}KNN\\ k = 20\end{tabular}                          & 0.05 & 0.06 \\ \hline
\begin{tabular}[c]{@{}c@{}}Decision Tree\\ Depth =  2\end{tabular}           & 0.04 & 0.11 & \begin{tabular}[c]{@{}c@{}}Decision Tree\\ Depth = 2\end{tabular}              & 0.06 & 0.11 & \begin{tabular}[c]{@{}c@{}}Decision Tree\\ Depth = 2\end{tabular}             & 0.06 & 0.06 \\ \hline
\begin{tabular}[c]{@{}c@{}}Logistic Regression\\ l. rate = 0.01\end{tabular} & 0.01 & 0.17 & \begin{tabular}[c]{@{}c@{}}Logistic Regression\\ l. rate = 0.05\end{tabular}   & 0.06 & 0.06 & \begin{tabular}[c]{@{}c@{}}Logistic Regression\\ l. rate = 0.005\end{tabular} & 0.06 & 0.06 \\ \hline
\end{tabular} }
\caption{APCR and BPCR classifying results using FRAV RGB database}
\label{APCR_BPCR_FRAV}
\end{table}


APCR and BPCR results are in table \ref{APCR_BPCR_FRAV}. In general, results are very good because values are lower than 0.5. With SVM lineal kernel, all the samples are classified as negatives except when it has been used when LDA, that results are as good as the obtained with RBF kernel.\\

The best  result is obtained when SVM with RBF kernel has been used with C = 1 and using LDA with 1 component. LDA improves the results obtained when neither PCA nor just the classifier has been used, although the improved is not too much.\\

The misclassified samples are repeated among the classifiers. The two samples shown in figure \ref{fig:frav_miscl} represents the two most misclassified images, almost every classifier have classified it incorrectly.\\

\begin{figure}[htb]
\centering
\includegraphics[width=0.2\textwidth]{images_databases/frav_tablet_109.JPG}
\includegraphics[width=0.2\textwidth]{images_databases/frav_tablet_162.JPG}
%('False Positive: ', 'databases/from/attack_04/tablet_162.JPG') ('False Positive: ', 'databases/from/attack_04/tablet_109.JPG')
\caption{RGB FRAV misclassified samples.} \label{fig:frav_miscl}
\end{figure}

\subsection{FRAV RGB+NIR (feature level) database}
Results obtained at classifying RGB+NIR (feature level) database are shown following.\\

\begin{table}[htb]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{|c|c|c||c|c|c||c|c|c|}
\hline
\rowcolor[HTML]{ECF4FF}
Classifier                                                                   & APCR & BPCR & \begin{tabular}[|c]{@{}c@{}}Classifier + PCA\\ nº components = 463\end{tabular} & APCR & BPCR & \begin{tabular}[|c]{@{}c@{}}Classifier + LDA\\ nº components = 1\end{tabular} & APCR & BPCR \\ \hline
\begin{tabular}[c]{@{}c@{}}SVM - RBF\\ C = 2\end{tabular}                    & 0.02 & 0    & \begin{tabular}[c]{@{}c@{}}SVM - RBF\\ C = 5\end{tabular}                      & 0.02 & 0    & \begin{tabular}[c]{@{}c@{}}SVM - RBF\\ C = 0.1\end{tabular}                  & 0.04 & 0    \\ \hline
\begin{tabular}[c]{@{}c@{}}SVM - lineal\\ C = 0.005\end{tabular}             & 0    & 1    & \begin{tabular}[c]{@{}c@{}}SVM - lineal\\ C = 0.001\end{tabular}               & 0    & 1    & \begin{tabular}[c]{@{}c@{}}SVM - lineal\\ C = 10\end{tabular}                & 0.05 & 0    \\ \hline
\begin{tabular}[c]{@{}c@{}}KNN\\ k = 6\end{tabular}                          & 0.09 & 0    & \begin{tabular}[c]{@{}c@{}}KNN\\ k = 12\end{tabular}                           & 0.12 & 0    & \begin{tabular}[c]{@{}c@{}}KNN\\ k = 10\end{tabular}                         & 0.04 & 0    \\ \hline
\begin{tabular}[c]{@{}c@{}}Decision Tree\\ Depth =  2\end{tabular}           & \textbf{0}    & \textbf{0}    & \begin{tabular}[c]{@{}c@{}}Decision Tree\\ Depth = 2\end{tabular}              & 0.01 & 0    & \begin{tabular}[c]{@{}c@{}}Decision Tree\\ Depth = 2\end{tabular}            & 0.05 & 0    \\ \hline
\begin{tabular}[c]{@{}c@{}}Logistic Regression\\ l. rate = 0.01\end{tabular} & \textbf{0}    & \textbf{0}    & \begin{tabular}[c]{@{}c@{}}Logistic Regression\\ l. rate = 0.05\end{tabular}   & 0.06 & 0    & \begin{tabular}[c]{@{}c@{}}Logistic Regression\\ l. rate = 0.05\end{tabular} & 0.07 & 0    \\ \hline
\end{tabular} }
\caption{APCR and BPCR classifying results using FRAV RGB+NIR (feature level) database}
\label{APCR_BPCR_FRAV_feature}
\end{table}

Table \ref{APCR_BPCR_FRAV_feature} shows the APCR and BPCR values that have been obtained for each classifier. Except for SVM with lineal kernel, which has classified all the samples as negatives when just the classifier has been used or if PCA has been applied too, classifications have produced good results, the APCR and BPCR values are very low, close to 0. In fact, Decision Tree and logistic regression classify correctly all the samples because APCR and BPCR are equal to 0. \\

PCA and LDA have not improved results significantly. SVM lineal with LDA does not classify all the samples as negatives. When PCA and LDA is applied with logistic regression and Decision tree, the classification is not perfect as it is when none is applied.\\

In general, the same samples are misclassified in the classification tasks. The two most misclassified samples are represented in figure \ref{fig:frav_feat_miscl}.\\

\begin{figure}[htb]
\centering
\includegraphics[width=0.2\textwidth]{images_databases/frav_rgb_151.JPG}
\includegraphics[width=0.2\textwidth]{images_databases/frav_nir_151.jpg}
\\
\includegraphics[width=0.2\textwidth]{images_databases/frav_rgb_128.JPG}
\includegraphics[width=0.2\textwidth]{images_databases/frav_nir_128.jpg}
%('False Positive: ', 'databases/RGB_NIR/RGB/attack_03/151.JPG') ('False Positive: ', 'databases/RGB_NIR/RGB/attack_03/128.JPG')
\caption{RGB+NIR FRAV (feature level) misclassified samples.} \label{fig:frav_feat_miscl}
\end{figure}

\subsection{FRAV RGB+NIR (classification level) database}
Results obtained when RGB+NIR FRAV database (classification level) is used are described.\\
\begin{table}[htb]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{|c|c|c||c|c|c||c|c|c|}
\hline
\rowcolor[HTML]{ECF4FF}
Classifier                                                                   & APCR & BPCR & \begin{tabular}[|c]{@{}c@{}}Classifier + PCA\\ nº components = 463\end{tabular} & APCR & BPCR & \begin{tabular}[|c]{@{}c@{}}Classifier + LDA\\ nº components = 1\end{tabular}  & APCR & BPCR \\ \hline
\begin{tabular}[c]{@{}c@{}}SVM - RBF\\ C = 10\end{tabular}                   & 0.01 & 0    & \begin{tabular}[c]{@{}c@{}}SVM - RBF\\ C = 1\end{tabular}                      & 0.02 & 0    & \begin{tabular}[c]{@{}c@{}}SVM - RBF\\ C = 2\end{tabular}                     & 0.01 & 0    \\ \hline
\begin{tabular}[c]{@{}c@{}}SVM - lineal\\ C = 0.001\end{tabular}             & 0    & 1    & \begin{tabular}[c]{@{}c@{}}SVM - lineal\\ C = 0.001\end{tabular}               & 0    & 1    & \begin{tabular}[c]{@{}c@{}}SVM - lineal\\ C = 1\end{tabular}                  & 0.01 & 0    \\ \hline
\begin{tabular}[c]{@{}c@{}}KNN\\ k = 6\end{tabular}                          & 0.32 & 0    & \begin{tabular}[c]{@{}c@{}}KNN\\ k = 14\end{tabular}                           & 0.04 & 0    & \begin{tabular}[c]{@{}c@{}}KNN\\ k = 6\end{tabular}                           & 0.01 & 0    \\ \hline
\begin{tabular}[c]{@{}c@{}}Decision Tree\\ Depth =  2\end{tabular}           & 0.04 & 0.07 & \begin{tabular}[c]{@{}c@{}}Decision Tree\\ Depth = 2\end{tabular}              & 0.05 & 0.07 & \begin{tabular}[c]{@{}c@{}}Decision Tree\\ Depth = 2\end{tabular}             & 0.01 & 0    \\ \hline
\begin{tabular}[c]{@{}c@{}}Logistic Regression\\ l. rate = 0.01\end{tabular} & 0    & 0.29 & \begin{tabular}[c]{@{}c@{}}Logistic Regression\\ l. rate = 0.05\end{tabular}   & 0.07 & 0    & \begin{tabular}[c]{@{}c@{}}Logistic Regression\\ l. rate = 0.005\end{tabular} & 0.02 & 0    \\ \hline
\end{tabular} }
\caption{APCR and BPCR classifying results using FRAV RGB+NIR (classification level) database}
\label{APCR_BPCR_FRAV_class}
\end{table}

APCER and BPCER results are summarized in table \ref{APCR_BPCR_FRAV_class}. Results are closer to 0, but none classifier classifies perfectly. There is possible to see that with LDA that APCR results are better and BPCR results are perfect.\\

SVM lineal classifier classifies incorrectly positives samples although PCA is used too, with LDA that does not happen.\\

In most of cases, classifiers just mis-classify one sample, the same sample represented in figure \ref{fig:frav_clas_miscl}. Classifiers that mis-classify more than one sample, the sample \ref{fig:frav_clas_miscl} is one of the misclassified.\\

\begin{figure}[htb]
\centering
\includegraphics[width=0.2\textwidth]{images_databases/frav_rgb_128.JPG}
\includegraphics[width=0.2\textwidth]{images_databases/frav_nir_128.jpg}
%('False Positive: ', 'databases/RGB_NIR/RGB/attack_03/128.JPG')
\caption{RGB+NIR FRAV (classification level) misclassified samples.} \label{fig:frav_clas_miscl}
\end{figure}

\subsection{MFSD-MSU database}
MFSD-MSU database results are described following.\\

\begin{table}[htb]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{|c|c|c||c|c|c||c|c|c|}
\hline
\rowcolor[HTML]{ECF4FF}
Classifier                                                                   & APCR & BPCR & \begin{tabular}[|c]{@{}c@{}}Classifier + PCA\\ nº components = 463\end{tabular} & APCR & BPCR & \begin{tabular}[|c]{@{}c@{}}Classifier + LDA\\ nº components = 1\end{tabular}   & APCR & BPCR \\ \hline
\begin{tabular}[c]{@{}c@{}}SVM - RBF\\ C = 0.01\end{tabular}                 & 0    & 1    & \begin{tabular}[c]{@{}c@{}}SVM - RBF\\ C = 0.001\end{tabular}                  & 0    & 1    & \begin{tabular}[c]{@{}c@{}}SVM - RBF\\ C = 1\end{tabular}                      & 0    & 1    \\ \hline
\begin{tabular}[c]{@{}c@{}}SVM - lineal\\ C = 0.001\end{tabular}             & 0    & 1    & \begin{tabular}[c]{@{}c@{}}SVM - lineal\\ C = 0.001\end{tabular}               & 0    & 1    & \begin{tabular}[c]{@{}c@{}}SVM - lineal\\ C = 10\end{tabular}                  & 0    & 1    \\ \hline
\begin{tabular}[c]{@{}c@{}}KNN\\ k = 24\end{tabular}                         & 0    & 1    & \begin{tabular}[c]{@{}c@{}}KNN\\ k = 30\end{tabular}                           & 0    & 1    & \begin{tabular}[c]{@{}c@{}}KNN\\ k = 30\end{tabular}                           & 0    & 1    \\ \hline
\begin{tabular}[c]{@{}c@{}}Decision Tree\\ Depth =  12\end{tabular}          & 0    & 1    & \begin{tabular}[c]{@{}c@{}}Decision Tree\\ Depth = 2\end{tabular}              & 0    & 1    & \begin{tabular}[c]{@{}c@{}}Decision Tree\\ Depth = 2\end{tabular}              & 0    & 1    \\ \hline
\begin{tabular}[c]{@{}c@{}}Logistic Regression\\ l. rate = 0.01\end{tabular} & 0    & 1    & \begin{tabular}[c]{@{}c@{}}Logistic Regression\\ l. rate = 0.0001\end{tabular} & 0    & 1    & \begin{tabular}[c]{@{}c@{}}Logistic Regression\\ l. rate = 0.0001\end{tabular} & 0    & 1    \\ \hline
\end{tabular} }
\caption{APCR and BPCR classifying results using MFSD-MSU database}
\label{APCR_BPCR_MFSD}
\end{table}

The classification with this database is not good because all the samples are classified as negatives, as could be seen in table \ref{APCR_BPCR_MFSD} where , independently of the classifier or if LDA and PCA are used, the BPCR value is always 1 and the APCR value is 0.\\

\section{Comparative among databases}
In this section it is going to discuss databases classification in common.

\subsection{FRAVs databases}
Three FRAVs databases are compared in order to discuss easier if NIR images, in general, help in order to detect anti-spoofing attacks. In order to do that, an due to the fact to the big amount of data, one classifier is chosen to do this comparative: SVM with RBF kernel.\\

\begin{figure}[htb]
\centering
\includegraphics[width=0.58\textwidth]{images/comparative/FRAVs_SVM_RBF_ROC.png}
\caption{Comparative among FRAV databases with SVM RBF.} \label{fig:FRAVS_SVM_comparative}
\end{figure}

In figure \ref{fig:FRAVS_SVM_comparative} are represented the three databases: In blue is represented RGB database, in green RGB+NIR FRAV database classification level and in magenta RGB+NIR FRAV database feature level. And the ROC curve with NIR work better, in fact, is almost perfect.\\

This image and the perfect APCR and BPCR result obtained with logistic regression and decision tree in the RGB+NIR feature level tends to conduce that NIR database are improved the results.\\

\subsection{CASIAs databases}
As the same as FRAVs databases, the comparative is going to be made with CASIAs databases: Image and Videos. In order to do that, KNN classifier is going to be used.\\

\begin{figure}[htb]
\centering
\includegraphics[width=0.58\textwidth]{images/comparative/CASIAs_KNN_ROC.png}
\caption{Comparative among CASIA databases with KNN.} \label{fig:CASIAS_KNN_comparative}
\end{figure}

In figure \ref{fig:CASIAS_KNN_comparative} is represented the comparative between image CASIA in blue and video CASIA database in green. As it is possible to see, the result is much better when just CASIA images databases are used, although CASIA video results are not bad.\\

\section{Executing time}
In this section, the time that has been necessary to carry out the training and testing processing described in this chapter  are exposed.\\

Each general experiment is formed by the CNN training and the classification, which involves the search of the optimal parameter for each classifier, and the metrics calculation. There are six general experiment, one per used databased:

\begin{description}[itemsep=2pt,topsep=8pt,parsep=0pt,partopsep=20pt]
 \item Process 1: when CASIA image database has been used.
 \item Process 2: when CASIA video database has been used.
 \item Process 3: when RGB FRAV database has been used.
 \item Process 4: when RGB+NIR FRAV database (feature level) has been used.
 \item Process 5: when RGB+NIR FRAV database (classification level) has been used.
 \item Process 6: when MFSD database has been used.
\end{description}

In table \ref{table:Executing_time} the time (minutes) is exposed for each process. All the processes differs (generally) just in the database, so the differences in time is because one database is bigger than other or because it is need to train two different neural networks as in RGB+NIR FRAV classification level.\\

\begin{table}[]
\centering
\begin{tabular}{|
>{\columncolor[HTML]{ECF4FF}}c |c|c|c|c|c|c|}
\hline
Process             & 1 & 1 & 2 & 3 & 5 & 4 \\
Executing Time(min) & 51.93m  & 152.40m  &  274.87m & 240.09m  & 432.78m  & 43.95m
  \\ \hline
\end{tabular}
\caption{Executing time}
\label{table:Executing_time}
\end{table}
